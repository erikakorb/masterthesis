{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3986d08e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import dask.dataframe as dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d7d0e5c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Functions to select a subsection of dataframes of interest from the WRBH dataframe ###\n",
    "#\n",
    "# this functions are written for the read.py file\n",
    "# which contains the additional parameters\n",
    "#\n",
    "# Hsup,thres_RL,thres_wind,observed = 0.3,1.,0.8,'cyg_x-3'         # for functions inside WRBH_select.py\n",
    "#\n",
    "#\n",
    "# nevertheless, these functions can work also as standalone\n",
    "# but we first have load the WRBH dataframe with dask\n",
    "# for instance:\n",
    "#\n",
    "# path_df =  './1mln_Z02_com/dataframes/'\n",
    "# n = 4\n",
    "#\n",
    "#\n",
    "# note that every function contain these parameter as argument:\n",
    "#\n",
    "# [path_df] is the path to the WRBH dataframe\n",
    "# [n] is the number of cores involved in the dask computation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34975583",
   "metadata": {},
   "source": [
    "# First and last timestep of binary ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b412ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Selects only first and last element of a pandas dataframe ###\n",
    "#\n",
    "# if in input there is a dask dataframe it is necessary to set to True the optional argument [dask]\n",
    "\n",
    "def first_last_ID(df,dask=False):   \n",
    "    first = df.drop_duplicates(subset=['ID'], keep='first',ignore_index=True)\n",
    "    last = df.drop_duplicates(subset=['ID'], keep='last',ignore_index=True)\n",
    "    \n",
    "    if dask ==True:\n",
    "        first = first.compute(num_workers = 4)\n",
    "        last = last.compute(num_workers = 4)\n",
    "       \n",
    "    df = pd.concat([first,last]).sort_values(['ID','BWorldtime'])  \n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52bc5585",
   "metadata": {},
   "source": [
    "# Observed candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "95b3226d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Select candidate binaries to compare with observed known binary ###\n",
    "#\n",
    "# [observed] to select binaries similar to one observed             e.g. 'cyg_x-3'\n",
    "# [firstlast] to select only first and last timestap for each ID if desired, default = False\n",
    "#\n",
    "# observed = 'cyg_x-3'\n",
    "\n",
    "def obs(path_df,n,Hsup,observed,firstlast=False):\n",
    "    if observed == 'cyg_x-3--Zd13':\n",
    "        # read WRBH with dask\n",
    "        WRBH = dd.read_csv(f'{path_df}WRBH.csv',blocksize= 128* 1024 * 1024)\n",
    "\n",
    "        # period taken from Singh 2002 (cited by Zdziarski 2013 as P=0.19969 days)\n",
    "        # given the fits on page 6 of Singh 2002, it could be an uncertainty of 0.00001 days\n",
    "        # in doubt, we can consider a larger range from 4.5 to 5.1 hours (we expect the true value to be 4.8 hours)\n",
    "        P_min, P_max = 4.5/(24*365), 5.1/(24*365)       # period converted from hours to years\n",
    "        WRBH_per = WRBH.loc[(P_min <= WRBH['Period']) & (WRBH['Period']<=P_max)]\n",
    "\n",
    "        # mass ranges from Zdziarski 2013, MNRAS, 429 \n",
    "        # only BH_mass_min = 3 Msun is modified to be coherent with SEVN settings\n",
    "        WR_mass_min, WR_mass_max = 7.5, 14.2     # Msun\n",
    "        BH_mass_min, BH_mass_max = 3, 4.5        # Msun\n",
    "        WR0_mass = ((WR_mass_min <= WRBH_per['Mass_0']) & (WRBH_per['Mass_0']<=WR_mass_max))\n",
    "        WR1_mass = ((WR_mass_min <= WRBH_per['Mass_1']) & (WRBH_per['Mass_1']<=WR_mass_max))\n",
    "        BH0_mass = ((BH_mass_min <= WRBH_per['Mass_0']) & (WRBH_per['Mass_0']<=BH_mass_max))\n",
    "        BH1_mass = ((BH_mass_min <= WRBH_per['Mass_1']) & (WRBH_per['Mass_1']<=BH_mass_max))\n",
    "        \n",
    "        # make sure to put e.g. a WR constrain on a WR and not to a BH\n",
    "        WR0_He = ((WRBH['PhaseBSE_0'] == 7) | (WRBH['PhaseBSE_0'] == 8) | (WRBH['PhaseBSE_0'] == 9))\n",
    "        WR0_sp = ((WRBH['Hsup_0'] < Hsup) & (WRBH['RemnantType_0']== 0)  & (WRBH['PhaseBSE_0']!= 12))\n",
    "        WR0 = (WR0_He | WR0_sp)\n",
    "        WR1_He = ((WRBH['PhaseBSE_1'] == 7) | (WRBH['PhaseBSE_1'] == 8) | (WRBH['PhaseBSE_1'] == 9))\n",
    "        WR1_sp = ((WRBH['Hsup_1'] < Hsup) & (WRBH['RemnantType_1']== 0) & (WRBH['PhaseBSE_1']!= 12))\n",
    "        WR1 = (WR1_He | WR1_sp)        \n",
    "        BH0,BH1 = (WRBH['PhaseBSE_0'] == 14), (WRBH['PhaseBSE_1'] == 14)\n",
    "        \n",
    "        # compute the dataframe\n",
    "        WRBH_obs = WRBH_per.loc[(WR0 & WR0_mass & BH1_mass & BH1) | (BH0 & BH0_mass & WR1_mass & WR1)]\n",
    "        WRBH_obs = WRBH_obs.compute(num_workers=n)\n",
    "        \n",
    "        # as optional it is possible to select only first and last timestep for each ID\n",
    "        if firstlast==True:\n",
    "            WRBH_obs = first_last_ID(WRBH_obs)\n",
    "            \n",
    "    \n",
    "    \n",
    "    elif observed == 'cyg_x-3--An22':\n",
    "        # read WRBH with dask\n",
    "        WRBH = dd.read_csv(f'{path_df}WRBH.csv',blocksize= 128* 1024 * 1024)\n",
    "\n",
    "        # period taken from Antokhin 2019 (cited by Antokhin 2022 as P=0.199684.. days)\n",
    "        # given the fits on page 5 of Antokhin 2019, it could be an uncertainty of 0.000001 days\n",
    "        # in doubt, we can consider a larger range from 4.5 to 5.1 hours (we expect the true value to be 4.8 hours)\n",
    "        P_min, P_max = 4.5/(24*365), 5.1/(24*365)       # period converted from hours to years\n",
    "        WRBH_per = WRBH.loc[(P_min <= WRBH['Period']) & (WRBH['Period']<=P_max)]\n",
    " \n",
    "        # mass ranges from Antokhin 2022, ApJ         \n",
    "        # from mass loss rate + smooth wind they estimate MWR+MBH = 18.8 Msun\n",
    "        # using M-Mdot relation from Nugis Lamers 2000 + Zdziarski 2013 they find\n",
    "        # MWR = 11.6 +- 1.2 Msun therefore MBH = 7.2 +- 1.2 Msun\n",
    "        WR_mass_min, WR_mass_max = 10.4, 12.8     # Msun\n",
    "        BH_mass_min, BH_mass_max = 6, 8.4       # Msun\n",
    "        WR0_mass = ((WR_mass_min <= WRBH_per['Mass_0']) & (WRBH_per['Mass_0']<=WR_mass_max))\n",
    "        WR1_mass = ((WR_mass_min <= WRBH_per['Mass_1']) & (WRBH_per['Mass_1']<=WR_mass_max))\n",
    "        BH0_mass = ((BH_mass_min <= WRBH_per['Mass_0']) & (WRBH_per['Mass_0']<=BH_mass_max))\n",
    "        BH1_mass = ((BH_mass_min <= WRBH_per['Mass_1']) & (WRBH_per['Mass_1']<=BH_mass_max))\n",
    "        \n",
    "        # make sure to put e.g. a WR constrain on a WR and not to a BH\n",
    "        WR0_He = ((WRBH['PhaseBSE_0'] == 7) | (WRBH['PhaseBSE_0'] == 8) | (WRBH['PhaseBSE_0'] == 9))\n",
    "        WR0_sp = ((WRBH['Hsup_0'] < Hsup) & (WRBH['RemnantType_0']== 0)  & (WRBH['PhaseBSE_0']!= 12))\n",
    "        WR0 = (WR0_He | WR0_sp)\n",
    "        WR1_He = ((WRBH['PhaseBSE_1'] == 7) | (WRBH['PhaseBSE_1'] == 8) | (WRBH['PhaseBSE_1'] == 9))\n",
    "        WR1_sp = ((WRBH['Hsup_1'] < Hsup) & (WRBH['RemnantType_1']== 0) & (WRBH['PhaseBSE_1']!= 12))\n",
    "        WR1 = (WR1_He | WR1_sp)        \n",
    "        BH0,BH1 = (WRBH['PhaseBSE_0'] == 14), (WRBH['PhaseBSE_1'] == 14)\n",
    "        \n",
    "        # compute the dataframe\n",
    "        WRBH_obs = WRBH_per.loc[(WR0 & WR0_mass & BH1_mass & BH1) | (BH0 & BH0_mass & WR1_mass & WR1)]\n",
    "        WRBH_obs = WRBH_obs.compute(num_workers=n)\n",
    "        \n",
    "        # as optional it is possible to select only first and last timestep for each ID\n",
    "        if firstlast==True:\n",
    "            WRBH_obs = first_last_ID(WRBH_obs)\n",
    "            \n",
    "        \n",
    "    elif observed == 'cyg_x-3--Ko17':\n",
    "        # read WRBH with dask\n",
    "        WRBH = dd.read_csv(f'{path_df}WRBH.csv',blocksize= 128* 1024 * 1024)\n",
    "\n",
    "        # period taken from Antokhin 2019 (even though also Koljonen+2017 recognize it from light curve)\n",
    "        # given the fits on page 5 of Antokhin 2019, it could be an uncertainty of 0.000001 days\n",
    "        # in doubt, we can consider a larger range from 4.5 to 5.1 hours (we expect the true value to be 4.8 hours)\n",
    "        P_min, P_max = 4.5/(24*365), 5.1/(24*365)       # period converted from hours to years\n",
    "        WRBH_per = WRBH.loc[(P_min <= WRBH['Period']) & (WRBH['Period']<=P_max)]\n",
    " \n",
    "        # mass ranges from Koljonen & Maccarone 2017      \n",
    "        # from luminosity-mass relation of Graefner+2011 \n",
    "        # and accounting for possible distances 7.4-10.2 kpc\n",
    "        # they estimate MWR = 8-10 or 11-14 i.e. overall MWR = 8-14\n",
    "        # accounting for orbital inclination and wind velocity they estimate MBH < 10 Msun\n",
    "        WR_mass_min, WR_mass_max = 8., 14.     # Msun\n",
    "        BH_mass_min, BH_mass_max = 3., 10.       # Msun\n",
    "        WR0_mass = ((WR_mass_min <= WRBH_per['Mass_0']) & (WRBH_per['Mass_0']<=WR_mass_max))\n",
    "        WR1_mass = ((WR_mass_min <= WRBH_per['Mass_1']) & (WRBH_per['Mass_1']<=WR_mass_max))\n",
    "        BH0_mass = ((BH_mass_min <= WRBH_per['Mass_0']) & (WRBH_per['Mass_0']<=BH_mass_max))\n",
    "        BH1_mass = ((BH_mass_min <= WRBH_per['Mass_1']) & (WRBH_per['Mass_1']<=BH_mass_max))\n",
    "        \n",
    "        # make sure to put e.g. a WR constrain on a WR and not to a BH\n",
    "        WR0_He = ((WRBH['PhaseBSE_0'] == 7) | (WRBH['PhaseBSE_0'] == 8) | (WRBH['PhaseBSE_0'] == 9))\n",
    "        WR0_sp = ((WRBH['Hsup_0'] < Hsup) & (WRBH['RemnantType_0']== 0)  & (WRBH['PhaseBSE_0']!= 12))\n",
    "        WR0 = (WR0_He | WR0_sp)\n",
    "        WR1_He = ((WRBH['PhaseBSE_1'] == 7) | (WRBH['PhaseBSE_1'] == 8) | (WRBH['PhaseBSE_1'] == 9))\n",
    "        WR1_sp = ((WRBH['Hsup_1'] < Hsup) & (WRBH['RemnantType_1']== 0) & (WRBH['PhaseBSE_1']!= 12))\n",
    "        WR1 = (WR1_He | WR1_sp)        \n",
    "        BH0,BH1 = (WRBH['PhaseBSE_0'] == 14), (WRBH['PhaseBSE_1'] == 14)\n",
    "        \n",
    "        # compute the dataframe\n",
    "        WRBH_obs = WRBH_per.loc[(WR0 & WR0_mass & BH1_mass & BH1) | (BH0 & BH0_mass & WR1_mass & WR1)]\n",
    "        WRBH_obs = WRBH_obs.compute(num_workers=n)\n",
    "        \n",
    "        # as optional it is possible to select only first and last timestep for each ID\n",
    "        if firstlast==True:\n",
    "            WRBH_obs = first_last_ID(WRBH_obs)\n",
    "    \n",
    "    else:\n",
    "        col_names = WRBH.columns.to_list()\n",
    "        WRBH_obs = pd.DataFrame(columns = col_names)  # create empty dataframe so the read.py file keeps working\n",
    "    \n",
    "    return WRBH_obs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59464451",
   "metadata": {},
   "source": [
    "# Roche Lobe filling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4ae7cf2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Select RL filling systems above a given threshold ###\n",
    "#\n",
    "# [thres_min] is the minimum R/RL filling ratio to consider    e.g. thres_min = thres_RL = 1.\n",
    "# [firstlast] to select only first and last timestap for each ID if desired, default = False\n",
    "\n",
    "def RL_filling(path_df,n,thres_min,firstlast=False):\n",
    "    # read WRBH with dask\n",
    "    WRBH = dd.read_csv(f'{path_df}WRBH.csv',blocksize= 128* 1024 * 1024)\n",
    "    \n",
    "    # compute the dataframe\n",
    "    WRBH_RL= WRBH.loc[(WRBH['RL0_fill'] >= thres_min) | (WRBH['RL1_fill'] >= thres_min)]\n",
    "    WRBH_RL = WRBH_RL.compute(num_workers=n)\n",
    "    \n",
    "    # as optional it is possible to select only first and last timestep for each ID\n",
    "    if firstlast==True:\n",
    "        WRBH_RL = first_last_ID(WRBH_RL)\n",
    "    \n",
    "    return WRBH_RL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c0028d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Select pure wind-fed systems (not yet completely RL_filling) ###\n",
    "#\n",
    "# [thres_min] is the minimum R/RL filling ratio to consider    e.g. thres_min = thres_wind = 0.8\n",
    "# [thres_max] is the maximum R/RL filling ratio to consider    e.g. thres_max = thres_RL = 1.\n",
    "# [firstlast] to select only first and last timestap for each ID if desired, default = False\n",
    "\n",
    "def RL_wind(path_df,n,thres_min,thres_max,firstlast=False):\n",
    "    # read WRBH with dask\n",
    "    WRBH = dd.read_csv(f'{path_df}WRBH.csv',blocksize= 128* 1024 * 1024)\n",
    "    \n",
    "    # compute the dataframe\n",
    "    WRBH_wind=WRBH.loc[((thres_max > WRBH['RL0_fill']) & (WRBH['RL0_fill'] >= thres_min)) | \n",
    "                   ((thres_max > WRBH['RL1_fill']) & (WRBH['RL1_fill'] >= thres_min))]\n",
    "    WRBH_wind = WRBH_wind.compute(num_workers=n)\n",
    "    \n",
    "    # as optional it is possible to select only first and last timestep for each ID\n",
    "    if firstlast==True:\n",
    "        WRBH_wind = first_last_ID(WRBH_wind)\n",
    "    \n",
    "    return WRBH_wind"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65950987",
   "metadata": {},
   "source": [
    "# Pure spectroscopic WR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c88a4590",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Pure spectroscopic WR (no He-naked yet) ###\n",
    "#\n",
    "# [Hsup] for surface hydrogen H<Hsup the star is a WR       e.g. Hsup = 0.3\n",
    "# [firstlast] to select only first and last timestap for each ID if desired, default = False\n",
    "\n",
    "def WR_spectro(path_df,n,Hsup,firstlast=False):\n",
    "    # read WRBH with dask\n",
    "    WRBH = dd.read_csv(f'{path_df}WRBH.csv',blocksize= 128* 1024 * 1024)\n",
    "    \n",
    "    # compute the dataframe\n",
    "    WR0_sp_pure = ((WRBH['Hsup_0'] < Hsup) & (WRBH['RemnantType_0']== 0 & (WRBH['PhaseBSE_0']!= 12)) \n",
    "               & (WRBH['PhaseBSE_0'] != 7) & (WRBH['PhaseBSE_0'] != 8) & (WRBH['PhaseBSE_0'] != 9))\n",
    "    WR1_sp_pure = ((WRBH['Hsup_1'] < Hsup) & (WRBH['RemnantType_1']== 0 & (WRBH['PhaseBSE_1']!= 12)) \n",
    "               & (WRBH['PhaseBSE_1'] != 7) & (WRBH['PhaseBSE_1'] != 8) & (WRBH['PhaseBSE_1'] != 9))\n",
    "    WRBH_sp = WRBH.loc[(WR0_sp_pure | WR1_sp_pure)]\n",
    "    \n",
    "    WRBH_sp = WRBH_sp.compute(num_workers=n)\n",
    "    \n",
    "    # as optional it is possible to select only first and last timestep for each ID\n",
    "    if firstlast==True:\n",
    "        WRBH_sp = first_last_ID(WRBH_sp)\n",
    "    \n",
    "    return WRBH_sp"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
