{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a32586c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### import libraries ###\n",
    "import os\n",
    "import shutil\n",
    "import dask.dataframe as dd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# # Function to read and write dataframes\n",
    "### define main function to process the dataframes obtained with results.py, read.py and WRBH_select.py ###\n",
    "\n",
    "# as input use the parameters from the results2.py file, located in the same working directory\n",
    "#\n",
    "# [version] is the SEVN2 version adopted                            e.g. '3.0.0-Spindevel'\n",
    "# [Nsim] is the number of simulations                               e.g. '1mln'\n",
    "# [Z] is the metallicity of the stars                               e.g. '02' for Z=0.02 solar metallicity\n",
    "# [kick] is the type of SN kick                                     e.g. 'unified265' has 265 as sigma of maxwellian\n",
    "# [SN] is the SN explosion prescription adopted                     e.g. 'del' for delayed or 'com' for compact\n",
    "# [n] number of cores involved in dask computation                  e.g.  4\n",
    "# [ppisn] if the debug includes only ppisn, also or excludes it     e.g. 'with','without','only'\n",
    "#\n",
    "# the following is an example:\n",
    "# version = '3.0.0-Spindevel_RLO'                                      # to select SEVN2 version\n",
    "# Nsim,Z,SN,kick = '1mln','015', 'com', 'unified265'                   # to select a set of simulations\n",
    "# n = 4                                                            # cores for dask computation\n",
    "# ppisn = 'only'\n",
    "\n",
    "def Read(version,Nsim,Z,SN,kick,n, ppisn):\n",
    "    ### input path with dataframes to be debugged ###\n",
    "    path_results = f'./v_{version}/{Nsim}_Z{Z}_{SN}_{kick}/'         # path to new folder with all useful results\n",
    "    path_df= f'{path_results}dataframes/'                     # where to write processed dataframes\n",
    "\n",
    "    ### paths where to save debugged files ###\n",
    "    path_ppisn = f'{path_results}ppisn_{ppisn}/'\n",
    "    path_ppisn_prog = f'{path_ppisn}progenitors/'                   # where to write progenitors\n",
    "    path_ppisn_rem = f'{path_ppisn}remnants/'                       # where to write remnants\n",
    "    path_ppisn_in_WRBH = f'{path_ppisn}initial_WRBH/'               # where to write initial timestamp for WRBH phase\n",
    "    path_ppisn_fin_WRBH = f'{path_ppisn}final_WRBH/'                # where to write final timestamp for WRBH phase\n",
    "\n",
    "    ### check directories exist or create them ###\n",
    "    path_list = [path_ppisn, path_ppisn_prog,path_ppisn_rem,path_ppisn_in_WRBH,path_ppisn_fin_WRBH]\n",
    "    for path in path_list:\n",
    "        os.makedirs(path, exist_ok=True)\n",
    "\n",
    "    ### copy files ###\n",
    "    _=shutil.copy2(f'{path_df}evolved.csv', path_ppisn)          # evolved.sh     \n",
    "\n",
    "\n",
    "    ##########################################\n",
    "    #### re-define condition for being a BH and a NS ###\n",
    "    MminBH = 3.  # minimum mass to be a BH i.e. who underwent a PPISN and has M<MminBH is a NS now\n",
    "\n",
    "    # if ppisn == 'with', the original analysis based on the PhaseBSE only was already considering\n",
    "    # compact objects with M<3 Msun that underwent a PPISN episode as BHs, so the original dataframes were already ok\n",
    "    if ppisn == 'with':\n",
    "        _=shutil.copy2(f'{path_df}WRBH.csv', path_ppisn)          # WRBH.csv   \n",
    "        _=shutil.copy2(f'{path_df}BHBH.csv', path_ppisn)          # BHBH.csv   \n",
    "        _=shutil.copy2(f'{path_df}BHNS.csv', path_ppisn)          # BHNS.csv \n",
    "\n",
    "    # otherwise select the compact objects formed after ppsin and decide whether to classify them as BH or NS\n",
    "    # and extract them from the WRBH, BHNS, BHBH files\n",
    "    else:\n",
    "        ### extract WRBH, BHBH and BHNS data previously identified only by condition on PhaseBSE via results.py ###\n",
    "        WRBH=dd.read_csv(f'{path_df}WRBH.csv', blocksize= 128* 1024 * 1024)                   # WRBH\n",
    "        BHBH=dd.read_csv(f'{path_df}BHBH.csv', blocksize= 128* 1024 * 1024)                   # BHBH\n",
    "        BHNS=dd.read_csv(f'{path_df}BHNS.csv', blocksize= 128* 1024 * 1024)                   # BHNS\n",
    "\n",
    "        for df,df_name in zip([WRBH,BHBH,BHNS],['WRBH','BHBH','BHNS']):\n",
    "            print(f'Elaborating {df_name}.csv')\n",
    "            # select only rows with at least one ppisn-derived compact object\n",
    "            co0_ppisn = (df['PhaseBSE_0'] == 14) & (df['Mass_0'] < MminBH)\n",
    "            co1_ppisn = (df['PhaseBSE_1'] == 14) & (df['Mass_1'] < MminBH)\n",
    "            df_ppisn = df.loc[co0_ppisn | co1_ppisn]\n",
    "            df_ppisn = df_ppisn.compute(num_workers=n)\n",
    "\n",
    "            # either write only the binaries with at least one ppisn-derived compact object\n",
    "            if ppisn == 'only':\n",
    "                df_ppisn.to_csv(f'{path_ppisn}{df_name}.csv')\n",
    "                df_ppisn = None\n",
    "\n",
    "            # or remove the ppisn-derived compact objects from the original dataframes\n",
    "            elif ppisn == 'without':\n",
    "                print('Merging dataframes')\n",
    "                df_select = dd.merge(df,df_ppisn, how='left', indicator=True)\n",
    "                df_clean = df_select.loc[df_select['_merge'] == 'left_only']\n",
    "                df_ppisn = None\n",
    "                df_clean.to_csv(f'{path_ppisn}{df_name}.csv',single_file=True)\n",
    "                df_clean = None\n",
    "            \n",
    "            # clean memory and print messages\n",
    "            df = None\n",
    "            print(f'Ended elaborating {df_name}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9698004",
   "metadata": {},
   "outputs": [],
   "source": [
    "# version = '3.0.0-Spindevel_RLO'                                      # to select SEVN2 version\n",
    "# Nsim,Z,SN,kick = '1mln','015', 'com', 'unified265'                   # to select a set of simulations\n",
    "# n = 4                                                            # cores for dask computation\n",
    "# ppisn = 'without'\n",
    "\n",
    "# Read2(version,Nsim,Z,SN,kick,n, ppisn)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
