{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3986d08e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b3226d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Select candidate binaries to compare with observed known binary ###\n",
    "#\n",
    "# [observed] to select binaries similar to one observed             e.g. 'cyg_x-3'\n",
    "# [WRBH] is the dataframe with all the timesteps while in WRBH\n",
    "# [path_df] is the path to the dataframes reduced by read.py        e.g. './1mln_Z02_del/dataframes/'\n",
    "#\n",
    "# this function is written for the read.py file\n",
    "# although it can work also as standalone, if we first specify the path_df and load the WRBH dataframe\n",
    "# for instance:\n",
    "#\n",
    "# observed = 'cyg_x-3'\n",
    "# path_df =  './1mln_Z02_del/dataframes/'\n",
    "# WRBH = pd.read_csv(f'{path_df}WRBH.csv',sep='\\s+')\n",
    "\n",
    "def obs(observed,WRBH,path_df):\n",
    "    if observed == 'cyg_x-3':\n",
    "\n",
    "        # period taken from Singh 2002 (cited by Zdziarski 2013 as P=0.19969 days)\n",
    "        # given the fits on page 6 of Singh 2002, it could be an uncertainty of 0.00001 days\n",
    "        # in doubt, we can consider a larger range from 4 to 6 hours (we expect the true value to be 4.8 hours)\n",
    "        P_min, P_max = 4*24*365, 6*24*365       # period converted from hours to years\n",
    "        WRBH_per = WRBH.loc[(P_min <= WRBH['Period']) & (WRBH['Period']<=P_max)]\n",
    "\n",
    "        # mass ranges from Zdziarski 2013, MNRAS, 429 \n",
    "        # only BH_mass_min = 3 Msun is modified to be coherent with SEVN settings\n",
    "        WR_mass_min, WR_mass_max = 7.5, 14.2     # Msun\n",
    "        BH_mass_min, BH_mass_max = 3, 4.5        # Msun\n",
    "        WR0_mass = ((WR_mass_min <= WRBH_per['Mass_0']) & (WRBH_per['Mass_0']<=WR_mass_max))\n",
    "        WR1_mass = ((WR_mass_min <= WRBH_per['Mass_1']) & (WRBH_per['Mass_1']<=WR_mass_max))\n",
    "        BH0_mass = ((BH_mass_min <= WRBH_per['Mass_0']) & (WRBH_per['Mass_0']<=BH_mass_max))\n",
    "        BH1_mass = ((BH_mass_min <= WRBH_per['Mass_1']) & (WRBH_per['Mass_1']<=BH_mass_max))\n",
    "        WRBH_obs = WRBH_per.loc[(WR0_mass & BH1_mass) | (BH0_mass & WR1_mass)]\n",
    "\n",
    "        # write the whole dataframe with candidates\n",
    "        WRBH_obs.to_csv(f'{path_df}WRBH_{observed}.csv')\n",
    "    \n",
    "    else:\n",
    "        col_names = WRBH.columns.to_list()\n",
    "        WRBH_obs = pd.DataFrame(columns = col_names)  # create empty dataframe so the read.py file keeps working\n",
    "    \n",
    "    return WRBH_obs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
