{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e299544d",
   "metadata": {},
   "source": [
    "# Preliminary operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c627f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "### import libraries ###\n",
    "import os\n",
    "import shutil\n",
    "import re\n",
    "import time\n",
    "import dask.dataframe as dd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import WRBH_select    # WRBH_select.py, in the same folder, to select subset of binaries from WRBH df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c51924c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# physical costants\n",
    "G4pi2 =  9953108.1      # G/(4 pi^2) in units of R_sun^3/(M_sun yr^2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af2b1387",
   "metadata": {},
   "source": [
    "# Function to read and write dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a90f3e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "### define main function to process the SEVN2 output dataframes ###\n",
    "\n",
    "# as input use the parameters from the results.py file, located in the same working directory\n",
    "#\n",
    "# [version] is the SEVN2 version adopted                            e.g. '3.0.0-Spindevel'\n",
    "# [Nsim] is the number of simulations                               e.g. '1mln'\n",
    "# [Z] is the metallicity of the stars                               e.g. '02' for Z=0.02 solar metallicity\n",
    "# [SN] is the SN explosion prescription adopted                     e.g. 'del' for delayed or 'com' for compact\n",
    "# [n] number of cores involved in dask computation                  e.g.  4\n",
    "# [Hsup] is the threshold for spectroscopic WR                      e.g. '0.3' for WR with H < 0.3 on surface\n",
    "#\n",
    "# the following is an example:\n",
    "# version = '3.0.0-Spindevel'                                      # to select SEVN2 version\n",
    "# Nsim,Z,SN= '1mln','02', 'com'                                    # to select a set of simulations\n",
    "# n = 4                                                            # cores for dask computation\n",
    "# Hsup= 0.3                                                        # for functions inside WRBH_select.py\n",
    "\n",
    "\n",
    "def Read(version,Nsim,Z,SN,Hsup,n):\n",
    "\n",
    "    start=time.time()\n",
    "    ### paths ###\n",
    "\n",
    "    ### input paths ###\n",
    "    path_to_sevn2 = f'./SEVN2-{version}/'                              # original folder with SEVN2 output\n",
    "    path_to_sevn2_output = f'{path_to_sevn2}run_scripts/sevn_output/'  # original sevn_output folder with SEVN2 output\n",
    "    path_evolved = f'{path_to_sevn2_output}evolved_0.dat'          # evolved binaries\n",
    "    path_log = f'{path_to_sevn2_output}logfile_0.dat'              # logfile\n",
    "    path_out = f'{path_to_sevn2_output}output_0.csv'               # output file\n",
    "\n",
    "    ### prepare new folder with results ###\n",
    "    path_results = f'./v_{version}/{Nsim}_Z{Z}_{SN}/'         # path to new folder with all useful results\n",
    "    path_to_copied = f'{path_results}copied/'                 # where to copy some of the simulated files\n",
    "\n",
    "    path_df= f'{path_results}dataframes/'                     # where to write processed dataframes\n",
    "    path_df_prog = f'{path_df}progenitors/'                   # where to write progenitors\n",
    "    path_df_rem = f'{path_df}remnants/'                       # where to write remnants\n",
    "    path_df_in_WRBH = f'{path_df}initial_WRBH/'               # where to write initial timestamp for WRBH phase\n",
    "    path_df_fin_WRBH = f'{path_df}final_WRBH/'                # where to write final timestamp for WRBH phase\n",
    "\n",
    "    ### check directories exist or create them ###\n",
    "    path_list = [path_results,path_to_copied,path_df,path_df_prog,path_df_rem,path_df_in_WRBH,path_df_fin_WRBH]\n",
    "    for path in path_list:\n",
    "        os.makedirs(path, exist_ok=True)\n",
    "\n",
    "\n",
    "    ### copy some original SEVN2 output files ###\n",
    "    _=shutil.copy2(f'{path_to_sevn2}run_scripts/run.sh', path_to_copied)          # run.sh        \n",
    "    _=shutil.copy2(f'{path_to_sevn2}run_scripts/listBin.dat', path_to_copied)     # listBin.dat\n",
    "    _=shutil.copy2(f'{path_to_sevn2_output}evolved_0.dat', path_to_copied)        # evolved_0.dat (contains seeds)\n",
    "    _=shutil.copy2(f'{path_to_sevn2_output}logfile_0.dat', path_to_copied)        # logfile_0.dat (contains key points)\n",
    "    _=shutil.copy2(f'{path_to_sevn2_output}launch_line.txt', path_to_copied)      # launch_line.txt (for bug fix)\n",
    "    _=shutil.copy2(f'{path_to_sevn2_output}used_params.svpar', path_to_copied)    # (for bug fix)\n",
    "    _=shutil.copy2(f'{path_to_sevn2_output}failed_0.dat', path_to_copied)         # (for bug fix)\n",
    "    \n",
    "    ##########################################\n",
    "\n",
    "    ### identify data of interest in SEVN output, evolved and log files ###\n",
    "\n",
    "    ### output file read with dask.dataframe ###\n",
    "    startout=time.time()\n",
    "    out=dd.read_csv(path_out, blocksize= 128* 1024 * 1024)                   # output file\n",
    "\n",
    "    ##########################################\n",
    "\n",
    "    ### identify data of interest in SEVN output, evolved and log files ###\n",
    "\n",
    "    ### output file read with dask.dataframe ###\n",
    "    startout=time.time()\n",
    "    out=dd.read_csv(path_out, blocksize= 128* 1024 * 1024)                   # output file\n",
    "\n",
    "    # binaries of compact objects\n",
    "    BH0,BH1 = (out['PhaseBSE_0'] == 14), (out['PhaseBSE_1'] == 14)\n",
    "    NS0,NS1 = (out['PhaseBSE_0'] == 13), (out['PhaseBSE_1'] == 13)\n",
    "\n",
    "    BHBH = out.loc[BH0 & BH1]                            # all rows with two BH\n",
    "    BHNS = out.loc[(BH0 & NS1) | (NS0 & BH1)]            # all rows with a BH and a NS\n",
    "\n",
    "    # BHs with a companion WR, either He-naked or spectroscopic (check is not a remnant in that case)\n",
    "    WR0_He = ((out['PhaseBSE_0'] == 7) | (out['PhaseBSE_0'] == 8) | (out['PhaseBSE_0'] == 9))\n",
    "    WR0_sp = ((out['Hsup_0'] < Hsup) & (out['RemnantType_0']== 0) & (out['PhaseBSE_0']!= 12))\n",
    "    WR0 = (WR0_He | WR0_sp)\n",
    "    WR1_He = ((out['PhaseBSE_1'] == 7) | (out['PhaseBSE_1'] == 8) | (out['PhaseBSE_1'] == 9))\n",
    "    WR1_sp = ((out['Hsup_1'] < Hsup) & (out['RemnantType_1']== 0) & (out['PhaseBSE_1']!= 12))\n",
    "    WR1 = (WR1_He | WR1_sp)\n",
    "\n",
    "    WRBH = out.loc[ (BH0 & WR1) | (WR0 & BH1) ]             # all rows with a WR and a BH\n",
    "\n",
    "    # compute dataframes\n",
    "    WRBH = WRBH.compute(num_workers=n) \n",
    "    BHBH = BHBH.compute(num_workers=n) \n",
    "    BHNS = BHNS.compute(num_workers=n) \n",
    "\n",
    "\n",
    "    endout=time.time()\n",
    "    print('Time to elaborate the output file [s]: ', endout-startout)\n",
    "\n",
    "    ### add columns for Roche Lobe filling ratio for WR + BH systems ###\n",
    "    WRBH['RL0_fill'] = WRBH['Radius_0'] / WRBH['RL0']  \n",
    "    WRBH['RL1_fill'] = WRBH['Radius_1'] / WRBH['RL1']\n",
    "\n",
    "    ####################################################################\n",
    "    ### extract CE counts from the log file with regular expressions ###\n",
    "\n",
    "    # in the logfile, CE lines have the following structure\n",
    "    # B;name;ID;CE;time;ID1:M1:MHe1:MCO1:phase1:rem_type1:ID2:M2:MHe2:MCO2:phase2:rem_type2:a:afin:fate\n",
    "    # where the labels '1' and '2' indicate respectively the values of the star\n",
    "    # that started (primary) or suffered(secondary) the CE\n",
    "    # all values refer at the beginning of the CE, exctept for 'afin' that is \n",
    "    # the semimajor axis after the CE\n",
    "\n",
    "    #regex_str=r'B;\\d+;\\d+;CE;(\\d+.\\d+);(\\d+):(\\d+.\\d+):\\d+.\\d+:\\d+.\\d+:\\d+:\\d+:(\\d+):(\\d+.\\d+):\\d+.\\d+:\\d+.\\d+:\\d+:\\d+:(\\d+\\d+):(\\d+\\d+):\\d+'\n",
    "    #fl = '\\d+.\\d+'\n",
    "    #exp = '\\d+.\\d+[e][+\\-]?\\d+'\n",
    "    #regex_str=fr'B;\\d+;(\\d+);CE;({fl});(\\d+):({exp}):{exp}:{exp}:\\d+:\\d+:(\\d+):({exp}):{exp}:{exp}:\\d+:\\d+:({exp}):({exp}):\\d+'\n",
    "    regex_str=r'B;\\d+;(\\d+);CE;'\n",
    "    with open(path_log,\"r\") as f:\n",
    "        CE_mask = re.findall(regex_str,f.read())  # find all the CE from the logfile and save the binary ID\n",
    "\n",
    "    CE = pd.DataFrame({'ID':np.asarray(CE_mask,dtype=int)})\n",
    "    CE = CE.groupby(['ID']).size().reset_index(name='NCE')    # count how many CE occurred in a given binary\n",
    "\n",
    "    ### read evolved file and add period column with pandas ###\n",
    "    evolved = pd.read_csv(path_evolved, sep='\\s+').rename(columns = {'#ID':'ID'})\n",
    "    evolved['Period'] = np.sqrt(evolved['a']**3 / (G4pi2*(evolved['Mass_0']+evolved['Mass_1']))) # Kepler 3rd law\n",
    "\n",
    "    ### add CE info on dataframes of interest ###\n",
    "    evolved = pd.merge(evolved,CE, on='ID',how='left')\n",
    "    BHBH = pd.merge(BHBH,CE, on='ID',how='left')\n",
    "    BHNS = pd.merge(BHNS,CE, on='ID',how='left')\n",
    "\n",
    "    ### write reduced dataframes ###\n",
    "    startmain=time.time()\n",
    "    print('Begin writing the main dataframes')\n",
    "\n",
    "    evolved.to_csv(f'{path_df}evolved.csv')\n",
    "    WRBH.to_csv(f'{path_df}WRBH.csv')\n",
    "    BHBH.to_csv(f'{path_df}BHBH.csv')\n",
    "    BHNS.to_csv(f'{path_df}BHNS.csv')\n",
    "\n",
    "    endmain = time.time()\n",
    "    print(f'Ended writing the main dataframes in [s]', endmain-startmain)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
